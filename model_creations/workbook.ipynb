{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import os\n",
    "import subprocess\n",
    "from ultralytics import YOLO\n",
    "import torch\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ниже код, где я обучал модель на 2000 размеченных картинках, сейчас он закомментирован, потому что в самом конце представленно итоговое обучение (уже на 4000 картинках)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f\"Torch version: {torch.__version__}\")\n",
    "# print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "\n",
    "# model = YOLO(\"yolov8m.pt\")\n",
    "# t_bank_path = \"tbank.yaml\"\n",
    "\n",
    "# model.train(\n",
    "#     data=t_bank_path,\n",
    "#     epochs=30,\n",
    "#     imgsz=640,\n",
    "#     device='cuda'\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Модель, обученная на 2000 размеченных картинках"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Загружена модель: C:/Users/roker/VSCode_projects/T_Bank_CV_API/T_Bank_CV_API/runs/detect/train4/weights/best.pt\n",
      "Ultralytics 8.3.197  Python-3.12.4 torch-2.5.1+cu121 CUDA:0 (NVIDIA GeForce RTX 4060 Laptop GPU, 8188MiB)\n",
      "Model summary (fused): 92 layers, 25,840,339 parameters, 0 gradients, 78.7 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.00.0 ms, read: 637.8687.2 MB/s, size: 32.2 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\roker\\VSCode_projects\\T_Bank_CV_API\\T_Bank_CV_API\\data\\splits\\labels\\val.cache... 141 images, 122 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 141/141  0.0s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 9/9 2.7it/s 3.4s0.3ss\n",
      "                   all        141         25      0.998       0.96      0.985      0.799\n",
      "Speed: 0.2ms preprocess, 13.1ms inference, 0.0ms loss, 0.5ms postprocess per image\n",
      "Results saved to \u001b[1mC:\\Users\\roker\\VSCode_projects\\T_Bank_CV_API\\T_Bank_CV_API\\runs\\detect\\val5\u001b[0m\n",
      "mAP50: 0.9853\n",
      "mAP50-95: 0.7987\n",
      "Precision: 0.9981\n",
      "Recall: 0.9600\n"
     ]
    }
   ],
   "source": [
    "model_path = \"C:/Users/roker/VSCode_projects/T_Bank_CV_API/T_Bank_CV_API/runs/detect/train4/weights/best.pt\"\n",
    "model = YOLO(model_path)\n",
    "t_bank_path = \"tbank.yaml\"\n",
    "print(f\"Загружена модель: {model_path}\")\n",
    "\n",
    "\n",
    "metrics = model.val(data=t_bank_path, iou=0.5)\n",
    "print(f\"mAP50: {metrics.box.map50:.4f}\")\n",
    "print(f\"mAP50-95: {metrics.box.map:.4f}\")\n",
    "print(f\"Precision: {metrics.box.mp:.4f}\")\n",
    "print(f\"Recall: {metrics.box.mr:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- mAP50: 0.9853\n",
    "- mAP50-95: 0.7987\n",
    "- Precision: 0.9981\n",
    "- Recall: 0.9600\n",
    "\n",
    "Мы получили хорошие результаты на 2000 размеченных картинках. Используя файл creating_labels.py обогатим наши данные: пусть наша обученная модель разметит картинки, я проверю их, а потом подгружу в train и val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "У меня есть силы проверить еще 2000 изображений, их я только и добавлю. Добавил бы больше то и результат получил бы лучше, но он и так неплохой! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.197  Python-3.12.4 torch-2.5.1+cu121 CUDA:0 (NVIDIA GeForce RTX 4060 Laptop GPU, 8188MiB)\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.00.0 ms, read: 210.6231.8 MB/s, size: 21.2 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\roker\\VSCode_projects\\T_Bank_CV_API\\T_Bank_CV_API\\data\\splits\\labels\\test... 1904 images, 1651 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 1904/1904 4.3Kit/s 0.4s0.0s\n",
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: C:\\Users\\roker\\VSCode_projects\\T_Bank_CV_API\\T_Bank_CV_API\\data\\splits\\labels\\test.cache\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 119/119 4.7it/s 25.4s0.2s\n",
      "                   all       1904        296      0.994      0.878       0.95      0.889\n",
      "Speed: 0.2ms preprocess, 12.4ms inference, 0.0ms loss, 0.3ms postprocess per image\n",
      "Results saved to \u001b[1mC:\\Users\\roker\\VSCode_projects\\T_Bank_CV_API\\T_Bank_CV_API\\runs\\detect\\val4\u001b[0m\n",
      "mAP50: 0.9504\n",
      "mAP50-95: 0.8891\n",
      "Precision: 0.9940\n",
      "Recall: 0.8784\n"
     ]
    }
   ],
   "source": [
    "metrics = model.val(data=t_bank_path,split='test', iou=0.5)\n",
    "print(f\"mAP50: {metrics.box.map50:.4f}\")\n",
    "print(f\"mAP50-95: {metrics.box.map:.4f}\")\n",
    "print(f\"Precision: {metrics.box.mp:.4f}\")\n",
    "print(f\"Recall: {metrics.box.mr:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сначала попробуем протестировать уже обученную модель (в test добавил 2000 проверенных изображений)\n",
    "\n",
    "- mAP50: 0.9504\n",
    "- mAP50-95: 0.8891\n",
    "- Precision: 0.9940\n",
    "- Recall: 0.8784\n",
    "\n",
    "В целом, также хорошо. А теперь закинем эти 2000 изображений в train. Обучим, это и будет наша финальная модель. Всего для обучения использовалось 4000 размеченных изображений (2000 мною и 2000 моделью)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Модель, обученная на 4000 изображений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch version: 2.5.1+cu121\n",
      "CUDA available: True\n",
      "New https://pypi.org/project/ultralytics/8.3.198 available  Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.197  Python-3.12.4 torch-2.5.1+cu121 CUDA:0 (NVIDIA GeForce RTX 4060 Laptop GPU, 8188MiB)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=tbank.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=70, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8m.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=train6, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=C:\\Users\\roker\\VSCode_projects\\T_Bank_CV_API\\T_Bank_CV_API\\runs\\detect\\train6, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   3776275  ultralytics.nn.modules.head.Detect           [1, [192, 384, 576]]          \n",
      "Model summary: 169 layers, 25,856,899 parameters, 25,856,883 gradients, 79.1 GFLOPs\n",
      "\n",
      "Transferred 469/475 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access  (ping: 0.00.0 ms, read: 336.7381.1 MB/s, size: 28.6 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\roker\\VSCode_projects\\T_Bank_CV_API\\T_Bank_CV_API\\data\\splits\\labels\\train... 2583 images, 3247 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 3711/3711 2.8Kit/s 1.3s0.0s\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: C:\\Users\\roker\\VSCode_projects\\T_Bank_CV_API\\T_Bank_CV_API\\data\\splits\\labels\\train.cache\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.10.0 ms, read: 3.53.5 MB/s, size: 32.2 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\roker\\VSCode_projects\\T_Bank_CV_API\\T_Bank_CV_API\\data\\splits\\labels\\val.cache... 141 images, 122 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 141/141 70.1Kit/s 0.0s\n",
      "Plotting labels to C:\\Users\\roker\\VSCode_projects\\T_Bank_CV_API\\T_Bank_CV_API\\runs\\detect\\train6\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 77 weight(decay=0.0), 84 weight(decay=0.0005), 83 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mC:\\Users\\roker\\VSCode_projects\\T_Bank_CV_API\\T_Bank_CV_API\\runs\\detect\\train6\u001b[0m\n",
      "Starting training for 70 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       1/70      6.18G      1.086      4.522      1.168          3        640: 100% ━━━━━━━━━━━━ 232/232 2.2it/s 1:46<0.4ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 4.3it/s 1.2s0.4s\n",
      "                   all        141         25      0.888       0.32      0.343      0.221\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       2/70      6.16G      1.283       1.69      1.438          1        640: 100% ━━━━━━━━━━━━ 232/232 2.3it/s 1:42<0.4ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 4.5it/s 1.1s0.3s\n",
      "                   all        141         25      0.016       0.24    0.00827    0.00495\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       3/70      6.68G       1.35       1.66      1.515          6        640: 100% ━━━━━━━━━━━━ 232/232 1.9it/s 2:01<0.5s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 4.3it/s 1.2s0.4s\n",
      "                   all        141         25      0.811        0.4      0.444      0.286\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       4/70      6.69G       1.25       1.42      1.463          1        640: 100% ━━━━━━━━━━━━ 232/232 1.7it/s 2:16<0.5s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 4.5it/s 1.1s0.3s\n",
      "                   all        141         25      0.949        0.8      0.894      0.557\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       5/70       6.7G       1.17      1.351      1.391          5        640: 100% ━━━━━━━━━━━━ 232/232 1.5it/s 2:32<0.6s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 3.7it/s 1.4s0.4s\n",
      "                   all        141         25      0.936       0.76      0.823      0.586\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       6/70      6.71G      1.202      1.301      1.412          5        640: 100% ━━━━━━━━━━━━ 232/232 1.4it/s 2:51<0.7s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 4.6it/s 1.1s0.3s\n",
      "                   all        141         25      0.832       0.52      0.695      0.469\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       7/70      6.71G      1.108      1.228      1.365          3        640: 100% ━━━━━━━━━━━━ 232/232 2.3it/s 1:42<0.4ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 4.3it/s 1.2s0.4s\n",
      "                   all        141         25      0.991       0.88      0.894      0.593\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       8/70      6.72G      1.002     0.9629      1.303          2        640: 100% ━━━━━━━━━━━━ 232/232 1.9it/s 2:05<0.6s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 1.7it/s 3.0s0.7s\n",
      "                   all        141         25          1      0.798      0.901      0.688\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       9/70      6.71G      0.988     0.9618      1.252          1        640: 100% ━━━━━━━━━━━━ 232/232 1.8it/s 2:09<0.5s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 4.5it/s 1.1s0.3s\n",
      "                   all        141         25      0.992       0.88      0.909      0.652\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      10/70       6.7G      1.008     0.9582      1.283          3        640: 100% ━━━━━━━━━━━━ 232/232 2.2it/s 1:48<0.4ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 4.5it/s 1.1s0.3s\n",
      "                   all        141         25       0.99       0.84      0.896      0.637\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      11/70      6.64G     0.9454     0.8172      1.232          5        640: 100% ━━━━━━━━━━━━ 232/232 1.9it/s 1:59<0.5s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 4.5it/s 1.1s0.3s\n",
      "                   all        141         25      0.954      0.832      0.924      0.657\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      12/70       6.7G     0.9118     0.8919      1.219          1        640: 100% ━━━━━━━━━━━━ 232/232 1.8it/s 2:10<0.5s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 4.4it/s 1.1s0.3s\n",
      "                   all        141         25      0.953      0.805      0.919      0.625\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      13/70      6.71G     0.8771     0.7176      1.171          7        640: 100% ━━━━━━━━━━━━ 232/232 2.0it/s 1:59<0.5ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 4.4it/s 1.1s0.3s\n",
      "                   all        141         25      0.954       0.88      0.959      0.723\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      14/70      6.71G      0.938      0.861      1.198          2        640: 100% ━━━━━━━━━━━━ 232/232 1.9it/s 2:00<0.5s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 4.3it/s 1.2s0.4s\n",
      "                   all        141         25          1      0.916      0.933      0.686\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      15/70      6.71G      0.889     0.7617      1.199          4        640: 100% ━━━━━━━━━━━━ 232/232 1.9it/s 2:01<0.5s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 4.2it/s 1.2s0.4s\n",
      "                   all        141         25          1       0.91      0.971      0.691\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      16/70      6.26G     0.8353     0.8845      1.126          4        640: 100% ━━━━━━━━━━━━ 232/232 2.3it/s 1:40<0.4ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 4.5it/s 1.1s0.3s\n",
      "                   all        141         25      0.923       0.84      0.963      0.702\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      17/70      6.27G      0.875     0.7311      1.194          4        640: 100% ━━━━━━━━━━━━ 232/232 2.3it/s 1:40<0.4ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 4.5it/s 1.1s0.3s\n",
      "                   all        141         25      0.995       0.84      0.916      0.678\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      18/70      6.27G     0.8277     0.7077      1.164          7        640: 100% ━━━━━━━━━━━━ 232/232 2.3it/s 1:40<0.4ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 4.5it/s 1.1s0.3s\n",
      "                   all        141         25       0.99       0.88      0.974      0.725\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      19/70      6.24G     0.7487        0.7      1.079          4        640: 100% ━━━━━━━━━━━━ 232/232 2.3it/s 1:40<0.4ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 4.5it/s 1.1s0.3s\n",
      "                   all        141         25          1      0.877      0.954      0.744\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      20/70      6.25G     0.8239     0.6969      1.174          3        640: 100% ━━━━━━━━━━━━ 232/232 2.3it/s 1:41<0.4ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 4.4it/s 1.1s0.3s\n",
      "                   all        141         25      0.993       0.88      0.963      0.696\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      21/70      6.28G     0.8379     0.7529      1.157          9        640: 100% ━━━━━━━━━━━━ 232/232 2.3it/s 1:40<0.4ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 4.5it/s 1.1s0.3s\n",
      "                   all        141         25      0.994       0.88      0.922      0.701\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      22/70      6.19G     0.7951     0.6157      1.126          2        640: 100% ━━━━━━━━━━━━ 232/232 2.3it/s 1:40<0.4ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 4.3it/s 1.2s0.4s\n",
      "                   all        141         25      0.961      0.988      0.992       0.76\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      23/70      6.25G     0.7978     0.7176      1.112          7        640: 100% ━━━━━━━━━━━━ 232/232 2.3it/s 1:41<0.4ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 4.4it/s 1.1s0.3s\n",
      "                   all        141         25      0.992       0.88       0.95      0.718\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      24/70      6.24G      0.727     0.5949      1.086          3        640: 100% ━━━━━━━━━━━━ 232/232 2.3it/s 1:41<0.4ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 4.2it/s 1.2s0.3s\n",
      "                   all        141         25      0.954          1      0.992      0.768\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      25/70      6.71G     0.7598     0.6195      1.103          4        640: 100% ━━━━━━━━━━━━ 232/232 2.0it/s 1:59<0.5s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 4.3it/s 1.2s0.4s\n",
      "                   all        141         25      0.979       0.88      0.959      0.725\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      26/70      6.71G     0.7438     0.6067      1.078          2        640: 100% ━━━━━━━━━━━━ 232/232 1.9it/s 2:02<0.5s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 4.6it/s 1.1s0.3s\n",
      "                   all        141         25       0.96      0.951      0.974      0.748\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      27/70      6.63G     0.7407      0.621      1.082          2        640: 100% ━━━━━━━━━━━━ 232/232 1.9it/s 1:59<0.5s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 4.2it/s 1.2s0.4s\n",
      "                   all        141         25      0.986       0.92      0.983      0.736\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      28/70      6.69G     0.6948     0.5592       1.05          2        640: 100% ━━━━━━━━━━━━ 232/232 1.7it/s 2:16<0.5s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 3.8it/s 1.3s0.4s\n",
      "                   all        141         25      0.949          1      0.992      0.754\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      29/70      6.71G     0.7854     0.6695      1.152          1        640: 100% ━━━━━━━━━━━━ 232/232 0.9it/s 4:16<1.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 3.7it/s 1.3s0.4s\n",
      "                   all        141         25          1      0.988      0.995      0.784\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      30/70       6.7G     0.7302     0.5471       1.11          2        640: 100% ━━━━━━━━━━━━ 232/232 2.0it/s 1:59<0.5ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 4.5it/s 1.1s0.3s\n",
      "                   all        141         25      0.925      0.991      0.989      0.748\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      31/70      6.72G     0.7279     0.6119      1.072          2        640: 100% ━━━━━━━━━━━━ 232/232 2.2it/s 1:44<0.4ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 4.5it/s 1.1s0.3s\n",
      "                   all        141         25      0.994       0.88      0.955      0.757\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      32/70      6.71G     0.7142      0.558      1.075          6        640: 100% ━━━━━━━━━━━━ 232/232 2.3it/s 1:40<0.4ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 4.3it/s 1.2s0.3s\n",
      "                   all        141         25          1      0.987      0.995      0.764\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      33/70       6.7G     0.7552     0.5991      1.111          4        640: 100% ━━━━━━━━━━━━ 232/232 2.3it/s 1:40<0.4ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 4.6it/s 1.1s0.3s\n",
      "                   all        141         25       0.96       0.96      0.986      0.782\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      34/70       6.7G     0.7158     0.5621      1.074          5        640: 100% ━━━━━━━━━━━━ 232/232 2.3it/s 1:40<0.4ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 4.3it/s 1.2s0.4s\n",
      "                   all        141         25       0.96      0.964      0.992       0.76\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      35/70      6.71G     0.7058     0.5914      1.067          1        640: 100% ━━━━━━━━━━━━ 232/232 2.3it/s 1:40<0.4ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 4.4it/s 1.1s0.3s\n",
      "                   all        141         25      0.921          1      0.984      0.762\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      36/70       6.7G     0.6736     0.5872      1.043          1        640: 100% ━━━━━━━━━━━━ 232/232 2.3it/s 1:40<0.4ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 4.4it/s 1.1s0.3s\n",
      "                   all        141         25          1      0.913      0.979      0.761\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      37/70      6.28G     0.6957     0.5069      1.064          4        640: 100% ━━━━━━━━━━━━ 232/232 2.3it/s 1:41<0.4ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 4.6it/s 1.1s0.3s\n",
      "                   all        141         25      0.957          1      0.995      0.785\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      38/70      6.26G     0.7144     0.5822      1.068          2        640: 100% ━━━━━━━━━━━━ 232/232 2.3it/s 1:41<0.4ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 4.5it/s 1.1s0.3s\n",
      "                   all        141         25      0.989       0.96      0.986      0.772\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      39/70      6.25G     0.7241     0.5685      1.085          1        640: 100% ━━━━━━━━━━━━ 232/232 2.3it/s 1:41<0.4ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 4.5it/s 1.1s0.3s\n",
      "                   all        141         25      0.989       0.96      0.989      0.769\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      40/70      6.72G     0.7053      0.555       1.07          5        640: 100% ━━━━━━━━━━━━ 232/232 2.3it/s 1:40<0.4ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 4.6it/s 1.1s0.3s\n",
      "                   all        141         25      0.961      0.996       0.99      0.768\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      41/70      6.29G     0.6646     0.6126      1.049          6        640: 100% ━━━━━━━━━━━━ 232/232 2.3it/s 1:42<0.4ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 4.2it/s 1.2s0.4s\n",
      "                   all        141         25      0.926      0.996      0.986      0.794\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      42/70      6.28G     0.7051      0.619      1.058          5        640: 100% ━━━━━━━━━━━━ 232/232 2.3it/s 1:41<0.4ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 4.5it/s 1.1s0.3s\n",
      "                   all        141         25      0.989       0.92      0.986      0.762\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      43/70      6.26G     0.6643     0.5477      1.048          3        640: 100% ━━━━━━━━━━━━ 232/232 2.3it/s 1:40<0.4ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 4.5it/s 1.1s0.3s\n",
      "                   all        141         25          1      0.995      0.995      0.792\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      44/70       6.7G     0.6942     0.6461      1.048          1        640: 100% ━━━━━━━━━━━━ 232/232 2.3it/s 1:40<0.4ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 4.5it/s 1.1s0.3s\n",
      "                   all        141         25      0.916       0.96      0.983      0.779\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      45/70      6.71G     0.6451     0.4618      1.032          6        640: 100% ━━━━━━━━━━━━ 232/232 2.3it/s 1:41<0.4ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 4.5it/s 1.1s0.3s\n",
      "                   all        141         25      0.984          1      0.995      0.777\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      46/70      6.27G     0.6515     0.4661     0.9879          4        640: 100% ━━━━━━━━━━━━ 232/232 2.3it/s 1:40<0.4ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 4.5it/s 1.1s0.3s\n",
      "                   all        141         25          1      0.996      0.995      0.799\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      47/70      6.24G     0.6331     0.5218      1.014          7        640: 100% ━━━━━━━━━━━━ 232/232 2.3it/s 1:40<0.4ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 4.4it/s 1.1s0.3s\n",
      "                   all        141         25       0.92          1      0.972      0.769\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      48/70      6.21G     0.6406     0.4877      1.024          2        640: 100% ━━━━━━━━━━━━ 232/232 2.3it/s 1:41<0.4ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 4.6it/s 1.1s0.3s\n",
      "                   all        141         25          1      0.989      0.995      0.786\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      49/70      6.25G     0.6667     0.5091      1.032          5        640: 100% ━━━━━━━━━━━━ 232/232 2.3it/s 1:41<0.4ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 4.1it/s 1.2s0.4s\n",
      "                   all        141         25       0.96      0.955      0.986      0.785\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      50/70      6.28G     0.5876     0.4659     0.9892          3        640: 100% ━━━━━━━━━━━━ 232/232 2.3it/s 1:40<0.4ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 4.5it/s 1.1s0.3s\n",
      "                   all        141         25          1      0.971      0.995      0.768\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      51/70      6.27G     0.6215       0.46      1.013          2        640: 100% ━━━━━━━━━━━━ 232/232 2.3it/s 1:40<0.4ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 4.5it/s 1.1s0.3s\n",
      "                   all        141         25      0.962       0.96      0.993      0.823\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      52/70      6.27G     0.5951     0.5013     0.9969          2        640: 100% ━━━━━━━━━━━━ 232/232 2.3it/s 1:40<0.4ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 4.5it/s 1.1s0.3s\n",
      "                   all        141         25      0.955          1      0.989      0.797\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      53/70      6.29G     0.6401     0.4844      1.024          8        640: 100% ━━━━━━━━━━━━ 232/232 2.3it/s 1:41<0.4ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 4.6it/s 1.1s0.3s\n",
      "                   all        141         25      0.981       0.96      0.984      0.779\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      54/70      6.26G     0.5955      0.434     0.9913          4        640: 100% ━━━━━━━━━━━━ 232/232 2.3it/s 1:40<0.4ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 4.3it/s 1.2s0.4s\n",
      "                   all        141         25      0.982       0.96      0.986      0.772\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      55/70      6.26G     0.5999     0.4287      1.003          3        640: 100% ━━━━━━━━━━━━ 232/232 2.3it/s 1:41<0.4ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 4.5it/s 1.1s0.3s\n",
      "                   all        141         25      0.961      0.994      0.992        0.8\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      56/70      6.28G     0.5692     0.4206     0.9795          4        640: 100% ━━━━━━━━━━━━ 232/232 2.3it/s 1:41<0.4ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 4.4it/s 1.1s0.3s\n",
      "                   all        141         25      0.986          1      0.995      0.787\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      57/70      6.25G     0.6102     0.4499      1.017          4        640: 100% ━━━━━━━━━━━━ 232/232 2.3it/s 1:40<0.4ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 4.5it/s 1.1s0.3s\n",
      "                   all        141         25          1      0.957      0.982      0.799\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      58/70      6.27G     0.5595     0.4208     0.9914          2        640: 100% ━━━━━━━━━━━━ 232/232 2.3it/s 1:40<0.4ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 4.4it/s 1.1s0.3s\n",
      "                   all        141         25      0.962          1      0.993        0.8\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      59/70      6.25G     0.5927     0.4961     0.9945          3        640: 100% ━━━━━━━━━━━━ 232/232 2.3it/s 1:40<0.4ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 4.6it/s 1.1s0.3s\n",
      "                   all        141         25      0.995       0.96      0.992      0.805\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      60/70      6.71G     0.5975     0.4591     0.9898          2        640: 100% ━━━━━━━━━━━━ 232/232 2.0it/s 1:59<0.5s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 4.4it/s 1.1s0.3s\n",
      "                   all        141         25      0.985          1      0.995      0.812\n",
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      61/70      6.62G     0.5274     0.3816     0.9078          0        640: 100% ━━━━━━━━━━━━ 232/232 2.3it/s 1:40<0.4ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 4.5it/s 1.1s0.3s\n",
      "                   all        141         25      0.993          1      0.995      0.803\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      62/70      6.65G     0.5431     0.4576     0.9021          1        640: 100% ━━━━━━━━━━━━ 232/232 2.3it/s 1:40<0.4ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 4.6it/s 1.1s0.3s\n",
      "                   all        141         25      0.989          1      0.995      0.818\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      63/70      6.26G     0.5335     0.4252     0.9112          2        640: 100% ━━━━━━━━━━━━ 232/232 2.3it/s 1:40<0.4ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 4.6it/s 1.1s0.3s\n",
      "                   all        141         25      0.989          1      0.995      0.811\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      64/70      6.28G     0.5193     0.4037      0.897          1        640: 100% ━━━━━━━━━━━━ 232/232 2.3it/s 1:39<0.4ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 4.6it/s 1.1s0.3s\n",
      "                   all        141         25       0.99          1      0.995      0.805\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      65/70      6.28G     0.4772     0.3712     0.8566          0        640: 100% ━━━━━━━━━━━━ 232/232 2.3it/s 1:40<0.4ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 4.5it/s 1.1s0.3s\n",
      "                   all        141         25      0.994          1      0.995      0.815\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      66/70      6.27G     0.4606     0.3452     0.8606          1        640: 100% ━━━━━━━━━━━━ 232/232 2.3it/s 1:40<0.4ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 4.4it/s 1.1s0.3s\n",
      "                   all        141         25      0.993          1      0.995      0.827\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      67/70      6.65G     0.4904     0.4066     0.8568          6        640: 100% ━━━━━━━━━━━━ 232/232 2.3it/s 1:40<0.4ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 4.3it/s 1.1s0.4s\n",
      "                   all        141         25      0.994          1      0.995      0.804\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      68/70      6.29G     0.4781     0.3632     0.8995          2        640: 100% ━━━━━━━━━━━━ 232/232 2.3it/s 1:39<0.4ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 4.5it/s 1.1s0.3s\n",
      "                   all        141         25      0.996          1      0.995      0.812\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      69/70      6.72G      0.484     0.3299     0.8771          2        640: 100% ━━━━━━━━━━━━ 232/232 2.0it/s 1:59<0.5ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 4.4it/s 1.1s0.3s\n",
      "                   all        141         25      0.992          1      0.995      0.807\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      70/70      6.72G     0.5088     0.3796     0.8706          2        640: 100% ━━━━━━━━━━━━ 232/232 2.2it/s 1:44<0.4ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 4.7it/s 1.1s0.3s\n",
      "                   all        141         25          1      0.997      0.995      0.812\n",
      "\n",
      "70 epochs completed in 2.187 hours.\n",
      "Optimizer stripped from C:\\Users\\roker\\VSCode_projects\\T_Bank_CV_API\\T_Bank_CV_API\\runs\\detect\\train6\\weights\\last.pt, 52.0MB\n",
      "Optimizer stripped from C:\\Users\\roker\\VSCode_projects\\T_Bank_CV_API\\T_Bank_CV_API\\runs\\detect\\train6\\weights\\best.pt, 52.0MB\n",
      "\n",
      "Validating C:\\Users\\roker\\VSCode_projects\\T_Bank_CV_API\\T_Bank_CV_API\\runs\\detect\\train6\\weights\\best.pt...\n",
      "Ultralytics 8.3.197  Python-3.12.4 torch-2.5.1+cu121 CUDA:0 (NVIDIA GeForce RTX 4060 Laptop GPU, 8188MiB)\n",
      "Model summary (fused): 92 layers, 25,840,339 parameters, 0 gradients, 78.7 GFLOPs\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 4.6it/s 1.1s0.3s\n",
      "                   all        141         25      0.993          1      0.995      0.827\n",
      "Speed: 0.2ms preprocess, 6.4ms inference, 0.0ms loss, 0.4ms postprocess per image\n",
      "Results saved to \u001b[1mC:\\Users\\roker\\VSCode_projects\\T_Bank_CV_API\\T_Bank_CV_API\\runs\\detect\\train6\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ultralytics.utils.metrics.DetMetrics object with attributes:\n",
       "\n",
       "ap_class_index: array([0])\n",
       "box: ultralytics.utils.metrics.Metric object\n",
       "confusion_matrix: <ultralytics.utils.metrics.ConfusionMatrix object at 0x000001EB10DEF6E0>\n",
       "curves: ['Precision-Recall(B)', 'F1-Confidence(B)', 'Precision-Confidence(B)', 'Recall-Confidence(B)']\n",
       "curves_results: [[array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
       "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
       "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
       "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
       "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
       "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
       "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
       "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
       "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
       "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
       "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
       "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
       "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
       "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
       "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
       "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
       "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
       "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
       "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
       "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
       "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
       "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
       "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
       "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
       "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
       "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
       "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
       "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
       "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
       "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
       "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
       "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
       "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
       "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
       "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
       "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
       "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
       "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
       "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
       "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
       "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
       "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[          1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           0]]), 'Recall', 'Precision'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
       "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
       "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
       "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
       "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
       "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
       "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
       "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
       "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
       "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
       "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
       "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
       "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
       "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
       "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
       "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
       "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
       "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
       "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
       "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
       "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
       "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
       "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
       "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
       "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
       "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
       "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
       "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
       "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
       "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
       "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
       "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
       "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
       "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
       "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
       "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
       "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
       "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
       "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
       "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
       "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
       "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[    0.59524,     0.59524,     0.65891,     0.67984,      0.6986,     0.71542,     0.71997,      0.7245,     0.73097,     0.73986,     0.75931,     0.76509,     0.77016,     0.77349,      0.7768,      0.7801,     0.78238,     0.78411,     0.78584,     0.78756,     0.78928,     0.79099,      0.7927,\n",
       "            0.79424,     0.79558,     0.79692,     0.79825,     0.79958,     0.80091,     0.80224,     0.80356,     0.80488,      0.8062,     0.81108,     0.81678,     0.82047,     0.82211,     0.82375,     0.82537,       0.827,     0.82862,     0.83023,     0.83185,     0.83388,     0.84115,     0.84755,\n",
       "            0.84834,     0.84913,     0.84991,      0.8507,     0.85148,     0.85226,     0.85304,     0.85382,      0.8546,     0.85538,     0.85616,     0.85693,     0.85771,     0.85848,     0.85925,     0.86002,     0.86079,     0.86156,     0.86216,     0.86243,      0.8627,     0.86297,     0.86323,\n",
       "             0.8635,     0.86377,     0.86404,     0.86431,     0.86457,     0.86484,     0.86511,     0.86537,     0.86564,     0.86591,     0.86617,     0.86644,     0.86671,     0.86697,     0.86724,     0.86751,     0.86777,     0.86804,      0.8683,     0.86857,     0.86883,      0.8691,     0.86937,\n",
       "            0.86963,      0.8699,     0.87016,     0.87042,     0.87069,     0.87095,     0.87122,     0.87148,     0.87175,     0.87201,     0.87227,     0.87254,      0.8728,     0.87307,     0.87333,     0.87359,     0.87385,     0.87412,     0.87438,     0.87464,     0.87491,     0.87517,     0.87543,\n",
       "            0.87569,     0.87596,     0.87622,     0.87648,     0.87674,       0.877,     0.87737,     0.87804,     0.87871,     0.87937,     0.88004,      0.8807,     0.88137,     0.88203,     0.88269,     0.88335,     0.88401,     0.88467,     0.88533,     0.88599,     0.88665,      0.8873,     0.88796,\n",
       "            0.88861,     0.88927,     0.88992,     0.89057,     0.89123,     0.89188,     0.89253,     0.89329,     0.89416,     0.89504,     0.89591,     0.89678,     0.89765,     0.89852,     0.89939,     0.90026,     0.90112,     0.90199,     0.90285,     0.90371,     0.90457,     0.90543,     0.90628,\n",
       "            0.90714,     0.90799,     0.90884,     0.90968,      0.9105,     0.91132,     0.91214,     0.91296,     0.91378,      0.9146,     0.91541,     0.91623,     0.91704,     0.91785,     0.91867,     0.91948,     0.92028,     0.92109,      0.9219,      0.9227,     0.92351,     0.92431,     0.92511,\n",
       "            0.92591,     0.92861,     0.93134,     0.93405,     0.93675,     0.93944,     0.94211,     0.94347,      0.9436,     0.94374,     0.94388,     0.94401,     0.94415,     0.94429,     0.94442,     0.94456,     0.94469,     0.94483,     0.94497,      0.9451,     0.94524,     0.94538,     0.94551,\n",
       "            0.94565,     0.94578,     0.94592,     0.94606,     0.94619,     0.94633,     0.94646,      0.9466,     0.94674,     0.94687,     0.94701,     0.94714,     0.94728,     0.94741,     0.94755,     0.94768,     0.94782,     0.94796,     0.94809,     0.94823,     0.94836,      0.9485,     0.94863,\n",
       "            0.94877,      0.9489,     0.94904,     0.94917,     0.94931,     0.94944,     0.94958,     0.94971,     0.94985,     0.94998,     0.95012,     0.95025,     0.95039,     0.95052,     0.95066,     0.95079,     0.95093,     0.95106,      0.9512,     0.95133,     0.95147,      0.9516,     0.95173,\n",
       "            0.95187,       0.952,     0.95214,     0.95227,     0.95241,     0.95254,     0.95267,     0.95281,     0.95294,     0.95308,     0.95321,     0.95335,     0.95348,     0.95361,     0.95375,     0.95388,     0.95401,     0.95415,     0.95428,     0.95442,     0.95455,     0.95468,     0.95482,\n",
       "            0.95495,     0.95508,     0.95522,     0.95535,     0.95549,     0.95562,     0.95575,     0.95589,     0.95602,     0.95615,     0.95629,     0.95642,     0.95655,     0.95669,     0.95682,     0.95695,     0.95709,     0.95722,     0.95735,     0.95748,     0.95762,     0.95775,     0.95788,\n",
       "            0.95802,     0.95815,     0.95828,     0.95841,     0.95855,     0.95868,     0.95881,     0.95895,     0.95908,     0.95921,     0.95934,     0.95948,     0.95961,     0.95974,     0.95987,     0.96001,     0.96014,     0.96027,      0.9604,     0.96053,     0.96067,      0.9608,     0.96093,\n",
       "            0.96106,      0.9612,     0.96133,     0.96146,     0.96165,     0.96193,     0.96221,     0.96249,     0.96277,     0.96305,     0.96333,     0.96361,     0.96389,     0.96417,     0.96445,     0.96473,     0.96501,     0.96529,     0.96557,     0.96585,     0.96613,     0.96641,     0.96669,\n",
       "            0.96696,     0.96724,     0.96752,      0.9678,     0.96808,     0.96835,     0.96863,     0.96891,     0.96919,     0.96946,     0.96974,     0.97002,     0.97029,     0.97057,     0.97085,     0.97112,      0.9714,     0.97167,     0.97195,     0.97222,      0.9725,     0.97277,     0.97305,\n",
       "            0.97332,      0.9736,     0.97387,     0.97415,     0.97442,      0.9747,     0.97497,     0.97525,     0.97552,     0.97579,     0.97607,     0.97634,     0.97661,     0.97689,     0.97716,     0.97743,      0.9777,     0.97798,     0.97825,     0.97852,     0.97879,     0.97906,     0.97934,\n",
       "            0.97961,     0.97988,     0.98015,      0.9804,     0.98047,     0.98055,     0.98062,     0.98069,     0.98077,     0.98084,     0.98091,     0.98098,     0.98106,     0.98113,      0.9812,     0.98128,     0.98135,     0.98142,      0.9815,     0.98157,     0.98164,     0.98171,     0.98179,\n",
       "            0.98186,     0.98193,     0.98201,     0.98208,     0.98215,     0.98222,      0.9823,     0.98237,     0.98244,     0.98252,     0.98259,     0.98266,     0.98273,     0.98281,     0.98288,     0.98295,     0.98303,      0.9831,     0.98317,     0.98324,     0.98332,     0.98339,     0.98346,\n",
       "            0.98353,     0.98361,     0.98368,     0.98375,     0.98383,      0.9839,     0.98397,     0.98404,     0.98412,     0.98419,     0.98426,     0.98433,     0.98441,     0.98448,     0.98455,     0.98462,      0.9847,     0.98477,     0.98484,     0.98491,     0.98499,     0.98506,     0.98513,\n",
       "             0.9852,     0.98528,     0.98535,     0.98542,     0.98549,     0.98557,     0.98564,     0.98571,     0.98578,     0.98585,     0.98593,       0.986,     0.98607,     0.98614,     0.98622,     0.98629,     0.98636,     0.98643,     0.98651,     0.98658,     0.98665,     0.98672,     0.98679,\n",
       "            0.98687,     0.98694,     0.98701,     0.98708,     0.98716,     0.98723,      0.9873,     0.98737,     0.98744,     0.98752,     0.98759,     0.98766,     0.98773,      0.9878,     0.98788,     0.98795,     0.98802,     0.98809,     0.98816,     0.98824,     0.98831,     0.98838,     0.98845,\n",
       "            0.98852,      0.9886,     0.98867,     0.98874,     0.98881,     0.98888,     0.98896,     0.98903,      0.9891,     0.98917,     0.98924,     0.98932,     0.98939,     0.98946,     0.98953,      0.9896,     0.98967,     0.98975,     0.98982,     0.98989,     0.98996,     0.99003,     0.99011,\n",
       "            0.99018,     0.99025,     0.99032,     0.99039,     0.99046,     0.99054,     0.99061,     0.99068,     0.99075,     0.99082,     0.99089,     0.99097,     0.99104,     0.99111,     0.99118,     0.99125,     0.99132,     0.99139,     0.99147,     0.99154,     0.99161,     0.99168,     0.99175,\n",
       "            0.99182,      0.9919,     0.99197,     0.99204,     0.99211,     0.99218,     0.99225,     0.99232,      0.9924,     0.99247,     0.99254,     0.99261,     0.99268,     0.99275,     0.99282,     0.99289,     0.99297,     0.99304,     0.99311,     0.99318,     0.99325,     0.99332,     0.99339,\n",
       "            0.99347,     0.99354,     0.99361,     0.99368,     0.99375,     0.99382,     0.99389,     0.99396,     0.99404,     0.99411,     0.99418,     0.99425,     0.99432,     0.99439,     0.99446,     0.99453,      0.9946,     0.99468,     0.99475,     0.99482,     0.99489,     0.99496,     0.99503,\n",
       "             0.9951,     0.99517,     0.99524,     0.99531,     0.99539,     0.99546,     0.99553,      0.9956,     0.99567,     0.99574,     0.99581,     0.99588,     0.99595,     0.99602,      0.9961,     0.99617,     0.99624,     0.99631,     0.99638,     0.99645,     0.99652,     0.99659,     0.99666,\n",
       "            0.99673,      0.9968,     0.99687,     0.99695,     0.99702,     0.99709,     0.99716,     0.99723,      0.9973,     0.99737,     0.99744,     0.99751,     0.99758,     0.99765,     0.99772,     0.99779,     0.99786,     0.99793,     0.99801,     0.99808,     0.99815,     0.99822,     0.99829,\n",
       "            0.99836,     0.99843,      0.9985,     0.99857,     0.99864,     0.99871,     0.99878,     0.99885,     0.99892,     0.99899,     0.99906,     0.99913,      0.9992,     0.99927,     0.99935,     0.99942,     0.99949,     0.99956,     0.99963,      0.9997,     0.99977,     0.99984,     0.99991,\n",
       "            0.99998,     0.99761,     0.99416,     0.99069,      0.9872,     0.98368,     0.98014,     0.97936,      0.9791,     0.97883,     0.97856,     0.97829,     0.97802,     0.97775,     0.97748,     0.97721,     0.97694,     0.97667,      0.9764,     0.97613,     0.97586,     0.97559,     0.97532,\n",
       "            0.97505,     0.97478,     0.97451,     0.97424,     0.97396,     0.97369,     0.97342,     0.97315,     0.97288,      0.9726,     0.97233,     0.97206,     0.97179,     0.97151,     0.97124,     0.97097,      0.9707,     0.97042,     0.97015,     0.96988,      0.9696,     0.96933,     0.96905,\n",
       "            0.96878,     0.96851,     0.96823,     0.96796,     0.96768,     0.96741,     0.96713,     0.96686,     0.96658,     0.96631,     0.96603,     0.96575,     0.96548,      0.9652,     0.96493,     0.96465,     0.96437,      0.9641,     0.96382,     0.96354,     0.96327,     0.96299,     0.96271,\n",
       "            0.96243,     0.96216,     0.96188,      0.9616,     0.96132,     0.96104,     0.96077,     0.96049,     0.96021,     0.95993,     0.95965,     0.95937,     0.95909,     0.95881,     0.95853,     0.95407,      0.9389,     0.93343,     0.93009,     0.92673,     0.92335,     0.91994,     0.91651,\n",
       "            0.91306,     0.90496,      0.8967,     0.88832,     0.87981,     0.87117,     0.86337,     0.86148,     0.85957,     0.85767,     0.85575,     0.85383,     0.85191,     0.84997,     0.84803,     0.84609,     0.84413,     0.84217,     0.84021,     0.83823,     0.80984,     0.80121,     0.79273,\n",
       "            0.78413,     0.77927,     0.77716,     0.77504,     0.77291,     0.77078,     0.76864,     0.76649,     0.76434,     0.76218,     0.76001,     0.75783,     0.75564,     0.75345,     0.75125,     0.74951,     0.74839,     0.74726,     0.74613,       0.745,     0.74386,     0.74273,     0.74159,\n",
       "            0.74045,     0.73931,     0.73816,     0.73702,     0.73587,     0.73472,     0.73356,     0.73241,     0.73125,     0.73009,     0.72893,     0.72777,      0.7266,     0.72544,     0.72427,     0.72309,     0.72192,     0.72074,     0.71957,     0.71839,     0.69637,     0.68348,     0.68237,\n",
       "            0.68126,     0.68014,     0.67903,     0.67791,     0.67679,     0.67567,     0.67454,     0.67341,     0.67229,     0.67116,     0.67002,     0.66889,     0.66775,     0.66662,     0.66548,     0.66433,     0.66319,     0.66204,      0.6609,     0.65975,     0.65859,     0.65744,     0.65629,\n",
       "            0.65513,     0.65397,     0.65281,     0.65164,     0.65048,     0.64931,     0.64693,     0.64297,     0.63898,     0.63497,     0.63094,     0.62688,      0.6228,      0.6187,     0.61457,     0.61067,     0.60803,     0.60537,     0.60271,     0.60004,     0.59735,     0.59466,     0.59195,\n",
       "            0.58924,     0.58651,     0.58378,     0.58103,     0.57827,     0.57551,     0.57273,     0.56863,     0.56336,     0.55805,     0.55271,     0.54732,     0.54189,     0.53642,     0.53091,      0.5271,     0.52392,     0.52072,     0.51751,     0.51428,     0.51104,     0.50779,     0.50452,\n",
       "            0.50124,     0.49794,     0.49463,     0.49131,     0.48797,     0.48461,     0.48124,     0.47786,     0.47445,     0.47104,     0.46761,     0.46416,      0.4607,     0.45722,     0.45373,     0.45022,      0.4467,     0.44315,      0.4396,     0.43232,     0.41962,     0.40672,      0.3936,\n",
       "            0.38473,     0.38006,     0.37537,     0.37065,     0.36591,     0.36113,     0.35633,      0.3515,     0.34664,     0.34175,     0.33684,     0.32221,     0.28284,     0.26863,      0.2598,     0.25089,     0.24188,     0.23278,     0.22359,      0.2143,     0.18104,     0.14682,     0.11822,\n",
       "           0.088726,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0]]), 'Confidence', 'F1'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
       "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
       "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
       "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
       "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
       "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
       "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
       "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
       "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
       "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
       "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
       "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
       "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
       "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
       "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
       "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
       "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
       "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
       "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
       "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
       "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
       "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
       "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
       "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
       "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
       "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
       "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
       "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
       "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
       "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
       "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
       "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
       "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
       "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
       "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
       "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
       "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
       "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
       "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
       "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
       "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
       "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[    0.42373,     0.42373,     0.49133,     0.51497,     0.53681,     0.55693,     0.56247,     0.56801,     0.57601,     0.58712,       0.612,     0.61955,     0.62623,     0.63064,     0.63506,     0.63948,     0.64255,     0.64489,     0.64723,     0.64956,      0.6519,     0.65424,     0.65658,\n",
       "            0.65871,     0.66055,      0.6624,     0.66424,     0.66609,     0.66793,     0.66978,     0.67163,     0.67347,     0.67532,      0.6822,      0.6903,      0.6956,     0.69795,     0.70031,     0.70267,     0.70503,     0.70739,     0.70974,      0.7121,     0.71508,     0.72585,     0.73544,\n",
       "            0.73663,     0.73781,       0.739,     0.74019,     0.74137,     0.74256,     0.74375,     0.74493,     0.74612,      0.7473,     0.74849,     0.74968,     0.75086,     0.75205,     0.75324,     0.75442,     0.75561,      0.7568,     0.75772,     0.75813,     0.75855,     0.75896,     0.75938,\n",
       "            0.75979,     0.76021,     0.76062,     0.76104,     0.76145,     0.76187,     0.76228,      0.7627,     0.76311,     0.76353,     0.76394,     0.76436,     0.76477,     0.76518,      0.7656,     0.76601,     0.76643,     0.76684,     0.76726,     0.76767,     0.76809,      0.7685,     0.76892,\n",
       "            0.76933,     0.76975,     0.77016,     0.77058,     0.77099,     0.77141,     0.77182,     0.77224,     0.77265,     0.77307,     0.77348,      0.7739,     0.77431,     0.77473,     0.77514,     0.77556,     0.77597,     0.77638,      0.7768,     0.77721,     0.77763,     0.77804,     0.77846,\n",
       "            0.77887,     0.77929,      0.7797,     0.78012,     0.78053,     0.78095,     0.78154,      0.7826,     0.78366,     0.78472,     0.78578,     0.78684,      0.7879,     0.78896,     0.79002,     0.79108,     0.79214,      0.7932,     0.79425,     0.79531,     0.79637,     0.79743,     0.79849,\n",
       "            0.79955,     0.80061,     0.80167,     0.80273,     0.80379,     0.80485,     0.80591,     0.80715,     0.80859,     0.81002,     0.81145,     0.81288,     0.81431,     0.81574,     0.81717,     0.81861,     0.82004,     0.82147,      0.8229,     0.82433,     0.82576,     0.82719,     0.82863,\n",
       "            0.83006,     0.83149,     0.83292,     0.83432,     0.83571,     0.83709,     0.83848,     0.83986,     0.84125,     0.84264,     0.84402,     0.84541,     0.84679,     0.84818,     0.84957,     0.85095,     0.85234,     0.85372,     0.85511,      0.8565,     0.85788,     0.85927,     0.86066,\n",
       "            0.86204,     0.86674,      0.8715,     0.87626,     0.88103,     0.88579,     0.89056,     0.89298,     0.89323,     0.89347,     0.89372,     0.89396,     0.89421,     0.89445,      0.8947,     0.89494,     0.89519,     0.89543,     0.89568,     0.89592,     0.89617,     0.89641,     0.89665,\n",
       "             0.8969,     0.89714,     0.89739,     0.89763,     0.89788,     0.89812,     0.89837,     0.89861,     0.89886,      0.8991,     0.89935,     0.89959,     0.89984,     0.90008,     0.90033,     0.90057,     0.90082,     0.90106,      0.9013,     0.90155,     0.90179,     0.90204,     0.90228,\n",
       "            0.90253,     0.90277,     0.90302,     0.90326,     0.90351,     0.90375,       0.904,     0.90424,     0.90449,     0.90473,     0.90498,     0.90522,     0.90547,     0.90571,     0.90595,      0.9062,     0.90644,     0.90669,     0.90693,     0.90718,     0.90742,     0.90767,     0.90791,\n",
       "            0.90816,      0.9084,     0.90865,     0.90889,     0.90914,     0.90938,     0.90963,     0.90987,     0.91012,     0.91036,      0.9106,     0.91085,     0.91109,     0.91134,     0.91158,     0.91183,     0.91207,     0.91232,     0.91256,     0.91281,     0.91305,      0.9133,     0.91354,\n",
       "            0.91379,     0.91403,     0.91428,     0.91452,     0.91477,     0.91501,     0.91525,      0.9155,     0.91574,     0.91599,     0.91623,     0.91648,     0.91672,     0.91697,     0.91721,     0.91746,      0.9177,     0.91795,     0.91819,     0.91844,     0.91868,     0.91893,     0.91917,\n",
       "            0.91942,     0.91966,      0.9199,     0.92015,     0.92039,     0.92064,     0.92088,     0.92113,     0.92137,     0.92162,     0.92186,     0.92211,     0.92235,      0.9226,     0.92284,     0.92309,     0.92333,     0.92358,     0.92382,     0.92407,     0.92431,     0.92455,      0.9248,\n",
       "            0.92504,     0.92529,     0.92553,     0.92578,     0.92613,     0.92666,     0.92718,      0.9277,     0.92822,     0.92874,     0.92926,     0.92978,     0.93031,     0.93083,     0.93135,     0.93187,     0.93239,     0.93291,     0.93343,     0.93396,     0.93448,       0.935,     0.93552,\n",
       "            0.93604,     0.93656,     0.93708,     0.93761,     0.93813,     0.93865,     0.93917,     0.93969,     0.94021,     0.94074,     0.94126,     0.94178,      0.9423,     0.94282,     0.94334,     0.94386,     0.94439,     0.94491,     0.94543,     0.94595,     0.94647,     0.94699,     0.94751,\n",
       "            0.94804,     0.94856,     0.94908,      0.9496,     0.95012,     0.95064,     0.95116,     0.95169,     0.95221,     0.95273,     0.95325,     0.95377,     0.95429,     0.95482,     0.95534,     0.95586,     0.95638,      0.9569,     0.95742,     0.95794,     0.95847,     0.95899,     0.95951,\n",
       "            0.96003,     0.96055,     0.96107,     0.96155,     0.96169,     0.96183,     0.96198,     0.96212,     0.96226,      0.9624,     0.96254,     0.96268,     0.96282,     0.96296,      0.9631,     0.96324,     0.96338,     0.96352,     0.96366,      0.9638,     0.96395,     0.96409,     0.96423,\n",
       "            0.96437,     0.96451,     0.96465,     0.96479,     0.96493,     0.96507,     0.96521,     0.96535,     0.96549,     0.96563,     0.96577,     0.96591,     0.96606,      0.9662,     0.96634,     0.96648,     0.96662,     0.96676,      0.9669,     0.96704,     0.96718,     0.96732,     0.96746,\n",
       "             0.9676,     0.96774,     0.96788,     0.96802,     0.96817,     0.96831,     0.96845,     0.96859,     0.96873,     0.96887,     0.96901,     0.96915,     0.96929,     0.96943,     0.96957,     0.96971,     0.96985,     0.96999,     0.97013,     0.97028,     0.97042,     0.97056,      0.9707,\n",
       "            0.97084,     0.97098,     0.97112,     0.97126,      0.9714,     0.97154,     0.97168,     0.97182,     0.97196,      0.9721,     0.97224,     0.97239,     0.97253,     0.97267,     0.97281,     0.97295,     0.97309,     0.97323,     0.97337,     0.97351,     0.97365,     0.97379,     0.97393,\n",
       "            0.97407,     0.97421,     0.97435,      0.9745,     0.97464,     0.97478,     0.97492,     0.97506,      0.9752,     0.97534,     0.97548,     0.97562,     0.97576,      0.9759,     0.97604,     0.97618,     0.97632,     0.97647,     0.97661,     0.97675,     0.97689,     0.97703,     0.97717,\n",
       "            0.97731,     0.97745,     0.97759,     0.97773,     0.97787,     0.97801,     0.97815,     0.97829,     0.97843,     0.97858,     0.97872,     0.97886,       0.979,     0.97914,     0.97928,     0.97942,     0.97956,      0.9797,     0.97984,     0.97998,     0.98012,     0.98026,      0.9804,\n",
       "            0.98054,     0.98069,     0.98083,     0.98097,     0.98111,     0.98125,     0.98139,     0.98153,     0.98167,     0.98181,     0.98195,     0.98209,     0.98223,     0.98237,     0.98251,     0.98265,      0.9828,     0.98294,     0.98308,     0.98322,     0.98336,      0.9835,     0.98364,\n",
       "            0.98378,     0.98392,     0.98406,      0.9842,     0.98434,     0.98448,     0.98462,     0.98476,     0.98491,     0.98505,     0.98519,     0.98533,     0.98547,     0.98561,     0.98575,     0.98589,     0.98603,     0.98617,     0.98631,     0.98645,     0.98659,     0.98673,     0.98687,\n",
       "            0.98702,     0.98716,      0.9873,     0.98744,     0.98758,     0.98772,     0.98786,       0.988,     0.98814,     0.98828,     0.98842,     0.98856,      0.9887,     0.98884,     0.98899,     0.98913,     0.98927,     0.98941,     0.98955,     0.98969,     0.98983,     0.98997,     0.99011,\n",
       "            0.99025,     0.99039,     0.99053,     0.99067,     0.99081,     0.99095,      0.9911,     0.99124,     0.99138,     0.99152,     0.99166,      0.9918,     0.99194,     0.99208,     0.99222,     0.99236,      0.9925,     0.99264,     0.99278,     0.99292,     0.99306,     0.99321,     0.99335,\n",
       "            0.99349,     0.99363,     0.99377,     0.99391,     0.99405,     0.99419,     0.99433,     0.99447,     0.99461,     0.99475,     0.99489,     0.99503,     0.99517,     0.99532,     0.99546,      0.9956,     0.99574,     0.99588,     0.99602,     0.99616,      0.9963,     0.99644,     0.99658,\n",
       "            0.99672,     0.99686,       0.997,     0.99714,     0.99728,     0.99743,     0.99757,     0.99771,     0.99785,     0.99799,     0.99813,     0.99827,     0.99841,     0.99855,     0.99869,     0.99883,     0.99897,     0.99911,     0.99925,     0.99939,     0.99954,     0.99968,     0.99982,\n",
       "            0.99996,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1]]), 'Confidence', 'Precision'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
       "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
       "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
       "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
       "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
       "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
       "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
       "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
       "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
       "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
       "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
       "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
       "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
       "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
       "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
       "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
       "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
       "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
       "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
       "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
       "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
       "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
       "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
       "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
       "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
       "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
       "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
       "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
       "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
       "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
       "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
       "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
       "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
       "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
       "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
       "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
       "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
       "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
       "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
       "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
       "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
       "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[          1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,     0.99522,     0.98839,     0.98155,     0.97472,     0.96789,     0.96105,     0.95956,     0.95905,     0.95853,     0.95802,      0.9575,     0.95699,     0.95647,     0.95595,     0.95544,     0.95492,     0.95441,     0.95389,     0.95338,     0.95286,     0.95234,     0.95183,\n",
       "            0.95131,      0.9508,     0.95028,     0.94976,     0.94925,     0.94873,     0.94822,      0.9477,     0.94719,     0.94667,     0.94615,     0.94564,     0.94512,     0.94461,     0.94409,     0.94358,     0.94306,     0.94254,     0.94203,     0.94151,       0.941,     0.94048,     0.93997,\n",
       "            0.93945,     0.93893,     0.93842,      0.9379,     0.93739,     0.93687,     0.93636,     0.93584,     0.93532,     0.93481,     0.93429,     0.93378,     0.93326,     0.93275,     0.93223,     0.93171,      0.9312,     0.93068,     0.93017,     0.92965,     0.92914,     0.92862,      0.9281,\n",
       "            0.92759,     0.92707,     0.92656,     0.92604,     0.92553,     0.92501,     0.92449,     0.92398,     0.92346,     0.92295,     0.92243,     0.92192,      0.9214,     0.92088,     0.92037,     0.91217,     0.88483,     0.87518,     0.86932,     0.86346,     0.85761,     0.85175,     0.84589,\n",
       "            0.84003,     0.82641,     0.81275,     0.79908,     0.78541,     0.77175,     0.75959,     0.75666,     0.75373,      0.7508,     0.74787,     0.74494,     0.74202,     0.73909,     0.73616,     0.73323,      0.7303,     0.72737,     0.72444,     0.72152,     0.68044,     0.66835,     0.65663,\n",
       "            0.64492,     0.63836,     0.63553,      0.6327,     0.62988,     0.62705,     0.62422,     0.62139,     0.61857,     0.61574,     0.61291,     0.61008,     0.60726,     0.60443,      0.6016,     0.59938,     0.59794,      0.5965,     0.59506,     0.59362,     0.59218,     0.59074,     0.58931,\n",
       "            0.58787,     0.58643,     0.58499,     0.58355,     0.58211,     0.58067,     0.57923,      0.5778,     0.57636,     0.57492,     0.57348,     0.57204,      0.5706,     0.56916,     0.56773,     0.56629,     0.56485,     0.56341,     0.56197,     0.56053,     0.53417,     0.51916,     0.51788,\n",
       "             0.5166,     0.51532,     0.51404,     0.51276,     0.51147,     0.51019,     0.50891,     0.50763,     0.50635,     0.50507,     0.50379,     0.50251,     0.50122,     0.49994,     0.49866,     0.49738,      0.4961,     0.49482,     0.49354,     0.49225,     0.49097,     0.48969,     0.48841,\n",
       "            0.48713,     0.48585,     0.48457,     0.48329,       0.482,     0.48072,     0.47812,      0.4738,     0.46949,     0.46517,     0.46086,     0.45654,     0.45222,     0.44791,     0.44359,     0.43954,     0.43681,     0.43408,     0.43134,     0.42861,     0.42588,     0.42314,     0.42041,\n",
       "            0.41768,     0.41494,     0.41221,     0.40947,     0.40674,     0.40401,     0.40127,     0.39726,     0.39214,     0.38701,     0.38189,     0.37676,     0.37164,     0.36651,     0.36139,     0.35787,     0.35494,     0.35201,     0.34908,     0.34615,     0.34322,     0.34029,     0.33736,\n",
       "            0.33444,     0.33151,     0.32858,     0.32565,     0.32272,     0.31979,     0.31686,     0.31394,     0.31101,     0.30808,     0.30515,     0.30222,     0.29929,     0.29636,     0.29343,     0.29051,     0.28758,     0.28465,     0.28172,     0.27577,     0.26552,     0.25527,     0.24502,\n",
       "            0.23818,     0.23462,     0.23105,     0.22748,     0.22392,     0.22035,     0.21679,     0.21322,     0.20966,     0.20609,     0.20253,     0.19205,     0.16471,     0.15515,      0.1493,     0.14344,     0.13758,     0.13172,     0.12587,     0.12001,     0.09953,    0.079223,    0.062823,\n",
       "           0.046422,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0]]), 'Confidence', 'Recall']]\n",
       "fitness: np.float64(0.8437176106710923)\n",
       "keys: ['metrics/precision(B)', 'metrics/recall(B)', 'metrics/mAP50(B)', 'metrics/mAP50-95(B)']\n",
       "maps: array([    0.82691])\n",
       "names: {0: 'logo'}\n",
       "nt_per_class: array([25])\n",
       "nt_per_image: array([19])\n",
       "results_dict: {'metrics/precision(B)': 0.9932053098868442, 'metrics/recall(B)': 1.0, 'metrics/mAP50(B)': 0.995, 'metrics/mAP50-95(B)': 0.8269084563012136, 'fitness': 0.8437176106710923}\n",
       "save_dir: WindowsPath('C:/Users/roker/VSCode_projects/T_Bank_CV_API/T_Bank_CV_API/runs/detect/train6')\n",
       "speed: {'preprocess': 0.1547808510396656, 'inference': 6.371156737523761, 'loss': 0.0001312056407728728, 'postprocess': 0.3817205669041327}\n",
       "stats: {'tp': [], 'conf': [], 'pred_cls': [], 'target_cls': [], 'target_img': []}\n",
       "task: 'detect'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"Torch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "\n",
    "model = YOLO(\"yolov8m.pt\")\n",
    "t_bank_path = \"tbank.yaml\"\n",
    "\n",
    "model.train(\n",
    "    data=t_bank_path,\n",
    "    epochs=70,\n",
    "    imgsz=640,\n",
    "    device='cuda'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Итог"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Только что обучили модельку. Нет сил размечать еще картинки, чтобы проверить какая модель лучше (на 4000 или на 2000), скорее всего та, что на 4000. Теперь это наша основная модель, её метрики примерно такие:\n",
    "- mAP50: ~ 0.95\n",
    "- mAP50-95: ~ 0.89\n",
    "\n",
    "(сужу по результатом на тестовой выборке для прошлой, менее крутой модели)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
